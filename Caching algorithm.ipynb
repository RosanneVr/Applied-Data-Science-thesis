{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd00ecf47b11f98bfd776c50f2e3d65e1dca601535a3e7ab66bd5a8ac1e4a31b223",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0ecf47b11f98bfd776c50f2e3d65e1dca601535a3e7ab66bd5a8ac1e4a31b223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "import sparql\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve data from the Utrecht Archives\n",
    "url = \"https://data.netwerkdigitaalerfgoed.nl/_api/datasets/hetutrechtsarchief/Dataset/services/Dataset/sparql\"\n",
    "\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "\n",
    "resp_list = []  \n",
    "offset = -10000\n",
    "\n",
    "for x in range(10):\n",
    "  offset = offset + 10000\n",
    "  queryformat =     \"query=PREFIX%20dc%3A%20%3Chttp%3A%2F%2Fpurl.org%2Fdc%2Felements%2F1.1%2F%3E%0APREFIX%20dct%3A%20%3Chttp%3A%2F%2Fpurl.org%2Fdc%2Fterms%2F%3E%0APREFIX%20sw%3A%20%3Chttp%3A%2F%2Fsemanticweb.cs.vu.nl%2F2009%2F11%2Fsem%2F%3E%0APREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0ASELECT%20%20%2A%0A%7B%0A%20%20%7B%0A%20%20%20%20select%20%3Fstreet%20%3Fyear%20%28count%20%28%3Fyear%29%20as%20%3Fcount%29%20where%0A%20%20%20%20%7B%0A%20%20%20%20%09%3Fsub%20dct%3Adate%20%3Fyear.%0A%20%20%20%20%20%20%09%3Fsub%20dct%3Aspatial%20%3Fstreet.%0A%20%20%09%09FILTER%20regex%28%3Fstreet%2C%20%22wiki%22%29%0A%09%7Dorder%20by%20%3Fyear%0A%20%20%7D%0A%7D%0A%0ALIMIT%2010000%20offset%20{}%0A%0A\".format(offset)\n",
    "  query = str(queryformat)\n",
    "  resp = requests.post(url, headers=headers, data=query)\n",
    "  respj = resp.json()\n",
    "  resp_list.extend(respj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deduplicate and create right VALUES input format for the POST request to Wikidata\n",
    "titles = list(set([item['street'] for item in resp_list]))\n",
    "titles = [x.replace('http://www.wikidata.org/entity/', '') for x in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving data from Wikidata\n",
    "wd_endpoint = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "loc_qry = \"\"\"\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "\n",
    "SELECT ?street ?streetLabel ?coords ?bagID ?city ?cityLabel ?citycoords ?s_class WHERE {\n",
    "VALUES ?street {wd:\"\"\" + \" wd:\".join([i for i in titles]) + \"\"\"}\n",
    "OPTIONAL {?street wdt:P625 ?coords.}\n",
    "OPTIONAL {?street wdt:P5207 ?bagID . }\n",
    "OPTIONAL {?street wdt:P131 ?city . }\n",
    "?street wdt:P31 ?s_class .\n",
    "?city wdt:P625 ?citycoords.\n",
    "FILTER(?s_class = wd:Q79007 || ?s_class =  wd:Q2039348 || ?s_class = wd:Q3957)\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],nl\". }\n",
    "BIND(REPLACE(str(?street), \"http://www.wikidata.org/entity/\", \"\") AS ?location)\n",
    "}\"\"\"\n",
    "\n",
    "result = sparql.query(wd_endpoint, loc_qry)\n",
    "res = result.fetchall()\n",
    "res = [sparql.unpack_row(row) for row in res]\n",
    "bb_locs = pd.DataFrame.from_records(res, columns=result.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the double year notations to periods\n",
    "count_df = pd.DataFrame (resp_list,columns=['street', 'year','count'])\n",
    "double = {\"street\":[],\"year\":[],\"count\":[]}\n",
    "\n",
    "for index, row in count_df.iterrows():\n",
    "    if len(row.year) > 4:\n",
    "        double[\"street\"].append(row.street)\n",
    "        double[\"year\"].append(row.year)\n",
    "        double[\"count\"].append(row.count)\n",
    "        row.year = np.nan\n",
    "\n",
    "count_df.dropna(subset=['year'])\n",
    "\n",
    "doubledf = DataFrame.from_dict(double)\n",
    "doubledf[['start_date','end_date']] = doubledf.year.str.split(\"/\",expand=True,)\n",
    "doubledf['start_date'] = doubledf['start_date'].astype(int)\n",
    "doubledf['end_date'] = doubledf['end_date'].astype(int)\n",
    "\n",
    "extraY = {\"street\":[],\"year\":[],\"count\":[]}\n",
    "year_range = []\n",
    "\n",
    "for row in doubledf.itertuples():\n",
    "    year_range = range(row.start_date , row.end_date+1)\n",
    "    for i in year_range: \n",
    "        extraY[\"street\"].append(row.street)\n",
    "        extraY[\"year\"].append(i)\n",
    "        extraY[\"count\"].append('1')\n",
    "\n",
    "extraYdf = DataFrame.from_dict(extraY)\n",
    "\n",
    "result = count_df.append(extraYdf, sort=False)\n",
    "result['count'] = result['count'].astype(int)\n",
    "count_result = result.groupby(['street','year']).agg(count = pd.NamedAgg(column='count', aggfunc='sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the number of data points per city per year\n",
    "municipality_df = pd.merge(count_result,bb_locs[['street','city', 's_class']],on='street', how='left')\n",
    "provinces = ['http://www.wikidata.org/entity/Q2039348', 'http://www.wikidata.org/entity/Q3957']\n",
    "province_df = municipality_df[municipality_df.s_class.isin(provinces)]\n",
    "city_df = municipality_df[~municipality_df.s_class.isin(provinces)]\n",
    "province_df= province_df[['street', 'year', 'count']]\n",
    "city_df = city_df[['city','year', 'count']]\n",
    "province_df = province_df.rename(columns = {'street':'city'})\n",
    "city_df = city_df.dropna()\n",
    "all_municipalities = city_df.append(province_df, sort=False)\n",
    "count_municipalities = all_municipalities.groupby(['city','year']).agg(count = pd.NamedAgg(column='count', aggfunc='sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSVs\n",
    "count_municipalities.to_csv('CityCountUtrechtsArchief.csv')\n",
    "count_result.to_csv(\"LocationCountUtrechtsArchief.csv\")\n",
    "bb_locs.to_csv(\"Wikidatalocations.csv\")"
   ]
  }
 ]
}